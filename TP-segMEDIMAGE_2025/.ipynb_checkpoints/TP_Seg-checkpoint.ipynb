{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ms_hFrhsmsLX"
   },
   "source": [
    "# **Practical Session - Medical image segmentation**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iiNBMkvCqDc5"
   },
   "source": [
    "# Introduction\n",
    "The goal of this practical session is to test different segmentation methods seen in the courses on different types of medical images: X-ray scanner (CT) for the segmentation of the kidneys, MRI of the brain for the segmentation of the corpus callosum, temporal sequences of MRI images for the segmentation of the heart (left ventricle for example), dermoscopic images for the segmentation of skin lesions.\n",
    "\n",
    "You will start by developing a (guided) pipelines to pre-process, identify and segment skin lesions in dermoscopic images. \n",
    "Then, you will have to develop a pipeline (not guided) for **AT LEAST** another application (segmentation of the kidneys, corpus callosum or heart).\n",
    "\n",
    "You will have to write code and comments where you see **XXXXXXXXXXXXXXXXXXXXX**\n",
    "\n",
    "**Deadline**: You will have to upload a single jupyter notebook .ipynb with your answers (code + text) before the deadline (please check on Ecampus/Moodle). \n",
    "\n",
    "**The uploaded file should be named 'TP_Seg_YOURSURNAME.ipynb'.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "quyziZSu8RyE"
   },
   "source": [
    "## Skin lesions\n",
    "\n",
    "A skin lesion is defined as a superficial growth or patch of the skin that is visually different and/or has a different texture than its surrounding area. Skin lesions, such as moles or birthmarks, can degenerate and become melanoma, one of the deadliest skin cancer (more than 60k deaths in 2015 worldwide). Its incidence has been increasing during the last decades, especially in the areas mostly populated by white people.\n",
    "\n",
    "The most effective treatment is an early detection followed by surgical excision. This is why several approaches for melanoma detection have been proposed in the last years (computer-aided diagnosis (CAD) )."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ti8fJID5GWGW"
   },
   "source": [
    "Let's start with downloading some dermoscopic images. You can use the following code and download them from my Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "FjkJwdwwagk8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are not using Colab. Please define working_dir with the absolute path to the folder where you downloaded the data\n"
     ]
    }
   ],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "  from google_drive_downloader import GoogleDriveDownloader as gdd\n",
    "\n",
    "  gdd.download_file_from_google_drive(file_id='1BoU4S9xFgKaCtquU03kZQbH3Yv42oU_-',\n",
    "                                      dest_path='./skinlesion.zip',\n",
    "                                      unzip=True)  \n",
    "else:\n",
    "  print('You are not using Colab. Please define working_dir with the absolute path to the folder where you downloaded the data')\n",
    "\n",
    "# Please modify working_dir only if you are using your Anaconda (and not Google Colab)\n",
    "# You should write the absolute path of your working directory with the data\n",
    "Working_directory=\"./\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "knNujEW_YTw1"
   },
   "source": [
    "You can list the content of the folder using the command line *!ls*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MfpT4vwRYSxC"
   },
   "outputs": [],
   "source": [
    "data_path = Working_directory + 'skinlesion'\n",
    "!ls './skinlesion'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bBFFPaQ8G2O1"
   },
   "source": [
    "All images are RGB images in format .jpg. You also have the corresponding ground truth (ie manual) segmentation in format .png "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KfxxLCMv1DhD"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "listImages=glob.glob(data_path + '/*.jpg')\n",
    "N=len(listImages)\n",
    "print('There are {} images'.format(N))\n",
    "print(listImages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QlPGO4cEHQ32"
   },
   "source": [
    "Let's plot one image with the corresponding segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qZdO7cCH0Ts_"
   },
   "outputs": [],
   "source": [
    "from skimage.io import imread\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import AxesGrid\n",
    "\n",
    "# Choose a figure and plot it with the ground truth segmentation\n",
    "indexIm=1\n",
    "filename = listImages[indexIm]\n",
    "im = imread(filename)\n",
    "print('im is composed of ', im.dtype, ' going from ', np.min(im), ' to ', np.max(im))\n",
    "filename_Segmentation = filename[:-4] + '_Segmentation.png'\n",
    "im_Seg = imread(filename_Segmentation) # Value 0 or 255\n",
    "print('im_Seg is composed of : ',im_Seg.dtype, ' - Max value: ', np.max(im_Seg), ' - Min value: ', np.min(im_Seg), ' - Unique values: ', np.unique(im_Seg))\n",
    "im_Seg_bool = im_Seg == 255 \n",
    "im_Seg_expand = np.expand_dims(im_Seg_bool, axis=2)\n",
    "im_mul_mask = (im_Seg_expand*im) # pixel-wise product\n",
    "\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "grid = AxesGrid(fig, 111,\n",
    "                nrows_ncols = (1, 3),\n",
    "                axes_pad = 0.5)\n",
    "grid[0].imshow(im)\n",
    "grid[0].axis('off')\n",
    "grid[0].set_title(\"Original image\")\n",
    "grid[1].imshow(im_Seg_bool,cmap='gray')\n",
    "grid[1].axis('off')\n",
    "grid[1].set_title(\"Mask\")\n",
    "grid[2].imshow(im_mul_mask)\n",
    "grid[2].axis('off')\n",
    "grid[2].set_title(\"Image with mask\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lORf60vNr52s"
   },
   "source": [
    "First, let's simplify the problem by using only the blue channel and rescaling the figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FZDcEZdQ8Ulf"
   },
   "outputs": [],
   "source": [
    "from skimage.transform import rescale\n",
    "from skimage import img_as_bool\n",
    "\n",
    "# We only select the blue channel to start\n",
    "imb=im[:,:,2]\n",
    "\n",
    "# We rescale to speed up computations\n",
    "imbr = np.uint8(rescale(imb, 0.25, anti_aliasing=True,  order=1, preserve_range=True))\n",
    "im_Seg_r =  rescale(im_Seg, 0.25, anti_aliasing=False, order=0,  preserve_range=True)\n",
    "im_Seg_r_bool = im_Seg_r==255 # binary mask\n",
    "\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "grid = AxesGrid(fig, 111,\n",
    "                nrows_ncols = (1, 2),\n",
    "                axes_pad = 0.5)\n",
    "grid[0].imshow(imb,cmap='gray')\n",
    "grid[0].axis('off')\n",
    "grid[0].set_title(\"Original image - one channel\")\n",
    "grid[1].imshow(imb*im_Seg_bool,cmap='gray')\n",
    "grid[1].axis('off')\n",
    "grid[1].set_title(\"Image with mask\")\n",
    "\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "grid = AxesGrid(fig, 111,\n",
    "                nrows_ncols = (1, 2),\n",
    "                axes_pad = 0.5)\n",
    "grid[0].imshow(imbr,cmap='gray')\n",
    "grid[0].axis('off')\n",
    "grid[0].set_title(\"Rescaled image\")\n",
    "grid[1].imshow(imbr*im_Seg_r_bool,cmap='gray')\n",
    "grid[1].axis('off')\n",
    "grid[1].set_title(\"Rescaled image with rescaled mask\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DEzg6uFLetnV"
   },
   "source": [
    "Now, let's try to use K-means to directly segment the image. We will use the scikit-learn implementation.\n",
    "\n",
    "You should choose the number of clusters. Start with 2 and then look what it happens when you increase the number of clusters.\n",
    "\n",
    "Be careful: Kmeans randomly assigns the labels of the clusters (0,1,2,...,K).\n",
    "\n",
    "**Question**: You need to propose a method to assign the label 1 to the cluster (or clusters) containing the skin lesion and 0 for the other clusters. Look at the different images and try simple solutions (look at the position of the lesion for instance...). You can use the Dice score, defined as $DSC=\\frac{2TP}{2TP+FP+FN}$ for boolean data, to quantitavely compare the reference segmentation with the one you estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ku4VpCYveYjz"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from skimage import morphology\n",
    "from scipy.spatial.distance import dice\n",
    "\n",
    "Ncluster=XXXXXX\n",
    "\n",
    "x, y = imbr.shape\n",
    "imFloat = np.array(imbr, dtype=np.float64) / 255 # transform into float for computational reason\n",
    "kmeans = KMeans(n_clusters=Ncluster) # use K-means algorithm \n",
    "kmeansSeg=kmeans.fit_predict(imFloat.reshape(-1,1)) # fit to the data reshaped as a 1D vector\n",
    "kmeansSeg=np.reshape(kmeansSeg,(x,y)) # reshape as the initial image\n",
    "#print(np.unique(kmeansSeg))\n",
    "\n",
    "#plt.figure()\n",
    "#plt.hist(kmeansSeg.reshape(-1,1))\n",
    "#plt.title('Histogram of estimated labels')\n",
    "\n",
    "index_lesion=XXXXXXXXX\n",
    "kmeansSeg_bool = kmeansSeg==index_lesion\n",
    "\n",
    "print('The dice similarity is ', 1-dice(kmeansSeg_bool.flatten(),im_Seg_r_bool.flatten()))\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(20, 12))\n",
    "grid = AxesGrid(fig, 111,\n",
    "                nrows_ncols = (1, 4),\n",
    "                axes_pad = 0.5)\n",
    "grid[0].imshow(imbr,cmap='gray')\n",
    "grid[0].contour(morphology.opening(kmeansSeg_bool, morphology.disk(1)), colors='green', linewidths=1)\n",
    "grid[0].axis('off')\n",
    "grid[0].set_title(\"Computed segmentation\")\n",
    "grid[1].imshow(imbr,cmap='gray')\n",
    "grid[1].contour(morphology.opening(im_Seg_r_bool, morphology.disk(1)), colors='red', linewidths=1)\n",
    "grid[1].axis('off')\n",
    "grid[1].set_title(\"Ground Truth segmentation\")\n",
    "grid[2].imshow(imbr,cmap='gray')\n",
    "grid[2].contour(morphology.opening(im_Seg_r_bool, morphology.disk(1)), colors='red', linewidths=1)\n",
    "grid[2].contour(morphology.opening(kmeansSeg_bool, morphology.disk(1)), colors='green', linewidths=1)\n",
    "grid[2].axis('off')\n",
    "grid[2].set_title(\"Comparison\")\n",
    "grid[3].imshow(kmeansSeg)\n",
    "grid[3].axis('off')\n",
    "grid[3].set_title(\"Clustering result\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7uxxshdJqOs9"
   },
   "source": [
    "# Mathematical Morphology\n",
    "\n",
    "You could also use the morphological operators seen during the previous lectures to segment the skin lesions. First, we will remind you some morphological operators that you could use to segment the lesion. Please note that the structural elements and the hyper-parameters have been randomly chosen... you should probably change them.\n",
    "\n",
    "**Question**: Propose a pipeline using morphological operators to segment the skin lesions and motivate your choices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yRYOYur7qBCl"
   },
   "outputs": [],
   "source": [
    "import skimage.morphology as morpho  \n",
    "\n",
    "def strel(forme,taille,angle=45):\n",
    "    \"\"\"renvoie un element structurant de forme  \n",
    "     'diamond'  boule de la norme 1 fermee de rayon taille\n",
    "     'disk'     boule de la norme 2 fermee de rayon taille\n",
    "     'square'   carre de cote taille (il vaut mieux utiliser taille=impair)\n",
    "     'line'     segment de langueur taille et d'orientation angle (entre 0 et 180 en degres)\n",
    "      (Cette fonction n'est pas standard dans python)\n",
    "    \"\"\"\n",
    "\n",
    "    if forme == 'diamond':\n",
    "        return morpho.selem.diamond(taille)\n",
    "    if forme == 'disk':\n",
    "        return morpho.selem.disk(taille)\n",
    "    if forme == 'square':\n",
    "        return morpho.selem.square(taille)\n",
    "    if forme == 'line':\n",
    "        angle=int(-np.round(angle))\n",
    "        angle=angle%180\n",
    "        angle=np.float32(angle)/180.0*np.pi\n",
    "        x=int(np.round(np.cos(angle)*taille))\n",
    "        y=int(np.round(np.sin(angle)*taille))\n",
    "        if x**2+y**2 == 0:\n",
    "            if abs(np.cos(angle))>abs(np.sin(angle)):\n",
    "                x=int(np.sign(np.cos(angle)))\n",
    "                y=0\n",
    "            else:\n",
    "                y=int(np.sign(np.sin(angle)))\n",
    "                x=0\n",
    "        rr,cc=morpho.selem.draw.line(0,0,y,x)\n",
    "        rr=rr-rr.min()\n",
    "        cc=cc-cc.min()\n",
    "        img=np.zeros((rr.max()+1,cc.max()+1) )\n",
    "        img[rr,cc]=1\n",
    "        return img\n",
    "    raise RuntimeError('Erreur dans fonction strel: forme incomprise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3xBCfxWV8wSK"
   },
   "outputs": [],
   "source": [
    "#fermeture par un disque\n",
    "sizeDisque=3\n",
    "disk=strel('disk',sizeDisque)\n",
    "closeDisk=morpho.closing(imbr,disk)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(closeDisk,cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a8vOUMPoceeG"
   },
   "outputs": [],
   "source": [
    "# Reconstruction par erosion\n",
    "RecEr=np.max(imbr) - morpho.reconstruction(np.max(imbr)-closeDisk,np.max(imbr)-imbr)\n",
    "plt.figure()\n",
    "plt.imshow(RecEr,cmap='gray')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_oBv_FjV9eVx"
   },
   "outputs": [],
   "source": [
    "# Overture (remove small bright parts)\n",
    "se=strel('disk',1)\n",
    "Open=morpho.opening(imbr,se)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(Open,cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UOiYUU2r9oYU"
   },
   "outputs": [],
   "source": [
    "from scipy import ndimage as ndi\n",
    "from skimage.segmentation import watershed \n",
    "from skimage.filters import rank\n",
    "from skimage.util import img_as_ubyte\n",
    "from skimage.morphology import disk\n",
    "\n",
    "#gradient morphologique de l'image initiale\n",
    "se=morpho.selem.disk(2)\n",
    "grad=morpho.dilation(imbr,se)-morpho.erosion(imbr,se)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(grad,cmap='gray')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CdCGgWsJ9kQa"
   },
   "outputs": [],
   "source": [
    "# Overture (remove small bright parts)\n",
    "se=strel('disk',2)\n",
    "Open=morpho.opening(closeDisk,se)\n",
    "\n",
    "# Minima regionaux\n",
    "maxIm=255\n",
    "temp=Open.copy()\n",
    "    \n",
    "for i in range(Open.shape[0]):\n",
    "    for j in range(Open.shape[1]):\n",
    "        if Open[i,j] < maxIm: \n",
    "            temp[i,j]=Open[i,j]+1\n",
    "reco=maxIm-morpho.reconstruction(maxIm-temp,maxIm-Open)\n",
    "minReg=np.uint8(reco)-Open\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(minReg,cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "#suppression des marqueurs trop petits\n",
    "tailleMin=1\n",
    "seM=strel('disk',tailleMin)\n",
    "minReg=morpho.opening(minReg,seM)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(minReg,cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "#ajout d'un marqueur sur le bord de l'image\n",
    "for i in range(minReg.shape[0]):\n",
    "    minReg[i,0]=1\n",
    "    minReg[i,minReg.shape[1]-1]=1\n",
    "for j in range(minReg.shape[1]):\n",
    "    minReg[0,j]=1\n",
    "    minReg[minReg.shape[0]-1,j]=1\n",
    "    \n",
    "plt.figure()\n",
    "plt.imshow(minReg,cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "#Any non-zero values in input are counted as features and zero values are considered the background.\n",
    "markers = ndi.label(minReg)[0]\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(markers,cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "# We use the watershed algorithm to compute the labels\n",
    "labels = watershed(grad, markers)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(labels,cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(imbr, cmap=plt.cm.gray)\n",
    "plt.imshow(labels, cmap=plt.cm.nipy_spectral, alpha=.5)\n",
    "plt.title(\"Segmented\")\n",
    "\n",
    "#%% visualiation du resultat\n",
    "values, counts = np.unique(labels, return_counts=True)\n",
    "print(values[np.argmax(counts)])\n",
    "segm=labels.copy()\n",
    "# Choose the greatest area\n",
    "index=values[np.argmax(counts)]\n",
    "segm=segm==index\n",
    "#NB: ce resultat peut servir d'initialisation pour une autre methode de segmentation (croissance de regions, segmentation markovienne, etc.)\n",
    "\n",
    "#superposition des contours de la segmentation a l'image initiale\n",
    "plt.figure()\n",
    "plt.imshow(imbr,cmap='gray')\n",
    "plt.contour(morphology.opening(segm, morphology.disk(1)), colors='red', linewidths=1)\n",
    "plt.show()       \n",
    "\n",
    "print('The dice similarity is ', 1-dice(segm.flatten(),im_Seg_r_bool.flatten()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HoRP-_DeGVY_"
   },
   "source": [
    "We could also use the values of the morphological gradient to find the markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QMb4C35tEYDv"
   },
   "outputs": [],
   "source": [
    "markers = grad < 1\n",
    "markers = ndi.label(markers)[0]\n",
    "\n",
    "labels = watershed(grad, markers)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(labels,cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(imbr, cmap=plt.cm.gray)\n",
    "plt.imshow(labels, cmap=plt.cm.nipy_spectral, alpha=.5)\n",
    "plt.title(\"Segmented\")\n",
    "\n",
    "#%% visualiation du resultat\n",
    "values, counts = np.unique(labels, return_counts=True)\n",
    "print(values[np.argmax(counts)])\n",
    "segm=labels.copy()\n",
    "# Choose the greatest area\n",
    "index=values[np.argmax(counts)]\n",
    "segm=segm==index\n",
    "#NB: ce resultat peut servir d'initialisation pour une autre methode de segmentation (croissance de regions, segmentation markovienne, etc.)\n",
    "\n",
    "#superposition des contours de la segmentation a l'image initiale\n",
    "plt.figure()\n",
    "plt.imshow(imbr,cmap='gray')\n",
    "plt.contour(morphology.opening(segm, morphology.disk(1)), colors='red', linewidths=1)\n",
    "plt.show()       \n",
    "\n",
    "print('The dice similarity is ', 1-dice(segm.flatten(),im_Seg_r_bool.flatten()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ymoCI-2wOhkd"
   },
   "source": [
    "## DullRazor (OPTIONAL)\n",
    "As you can see, there are several hairs within and outside the skin lesion image. One would like to remove and restore the hair regions to effectively segment and analyze the lesions. \n",
    "\n",
    "One of the simplest algorithms for Hair Removal is DullRazor proposed by Lee et al. It consists of three steps: (1) identification of the hair using morphological closing operation; (2) replacement of the hair pixels with normal (close) skin pixels using bilinear interpolation; and (3) smoothing the final result with a median filter.\n",
    "\n",
    "---\n",
    "\n",
    "*T.K. Lee, V. Ng, R. Gallagher, A. Coldman, D. McLean, A Dullrazor, Software approach to hair removal from images, J. Comput. Biol. Med. 27 (1997) 533–543*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0n03saAWzoB2"
   },
   "source": [
    "In the first part, authors propose to use (at least) three structuring element of type line with angles 0, 45 and 90. You can try to use more, if you think it would be useful. Then, a generalized grayscale closing image is obtained by taking the maximum response of the grayscale closing results at the previously specified\n",
    "directions. Finally, a binary hair mask image is created by thresholding the absolute\n",
    "difference between the original image and the generalized grayscale closing image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bAezErY80rF5"
   },
   "outputs": [],
   "source": [
    "XXXXXXXXXX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D6eCyhoCcFoO"
   },
   "source": [
    "Once computed the binary mask, we need to check whether each pixel of the mask is actually located within a thin and long structure, i.e. the hair structure; otherwise, it is rejected as noise.\n",
    "\n",
    "For each pixel inside the hair region of the mask, line segments are drawn in eight directions: up, down,. left, right and the four diagonals, radiating from the pixel until the segment reaches the non-hair region. These eight line segments form four straight lines centering at the pixel. Lengths of the lines are calculated and the longest one is noted. The longest line must be longer than a certain amount of pixels (to be chosen) and the other lines must be shorter than a certain amount of pixels (to be chosen). Otherwise, the pixel is rejected.\n",
    "\n",
    "When a pixel is verified to be inside the hair structure, its corresponding pixel in the\n",
    "original image is replaced, using bilinear interpolation, by other nearby non-hair pixel values along the perpendicular line to the longest one (the direction supposed to be the hair). Please choose carefully the pixels along the perpendicualar direction since there might be other hairs nearby (look at the intensity value and check whether it might be a skin pixel). \n",
    "\n",
    "Instead than using a bilinear interpolation, we could also use a more advanced solution based on inpaiting (you will see it in IMA206) such as: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aw6r51lA848F"
   },
   "outputs": [],
   "source": [
    "from skimage.restoration import inpaint\n",
    "image_result = inpaint.inpaint_biharmonic(imbr, mask, multichannel=False)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(image_result,cmap='gray')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BvhkYI7FYNdJ"
   },
   "source": [
    "Furthermore, authors also suggest to use a median filter to smooth the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OVb4tCglTWfC"
   },
   "outputs": [],
   "source": [
    "from scipy import ndimage\n",
    "\n",
    "medianFilt = ndimage.median_filter(imbr, size=20)\n",
    "\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "grid = AxesGrid(fig, 111,\n",
    "                nrows_ncols = (1, 2),\n",
    "                axes_pad = 0.5)\n",
    "grid[0].imshow(imbr,cmap='gray')\n",
    "grid[0].axis('off')\n",
    "grid[0].set_title(\"image\")\n",
    "grid[1].imshow(medianFilt,cmap='gray')\n",
    "grid[1].axis('off')\n",
    "grid[1].set_title(\"image filtered\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E3DnxZ0oeHjH"
   },
   "source": [
    "**Question (OPTIONAL)**: Implement the original (or a modified version) of the DullRazor algorithm. If you modify the algorithm, please explain why. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DHc3Gw26OhzK"
   },
   "source": [
    "## Otsu's algorithm\n",
    "\n",
    "Otsu's method looks for a threshold to split a gray-level image into two separate regions, based on their grey-level values. Since the maximum number of grey-levels is finite (and small, 256), we can use an exhaustive search.\n",
    "\n",
    "The grey-level threshold is the one that minimises the intra-class intensity variance, defined as a weighted sum of the variances of the two regions :\n",
    "\n",
    "$argmin_{\\tau}  \\omega_0(\\tau)\\sigma_0^2(\\tau) + \\omega_1(\\tau)\\sigma_1^2(t)$\n",
    "\n",
    "where\n",
    "\n",
    "- $\\sigma_0^2(\\tau)$ and $\\sigma_1^2(\\tau)$ are the intensity variances of the pixels in the first and second regions\n",
    "- $\\omega_0(\\tau)$ and $\\omega_1(\\tau)$ are the weights of the first and second regions \n",
    "\n",
    "Given the histogram of the image with $L$ bins where each bin $i$ has $p(i)$ pixels, we define the weights $\\omega_0(\\tau)$ and $\\omega_1(\\tau)$ as:\n",
    "\n",
    "- $\\omega_0(\\tau) = \\sum_{i=0}^{\\tau -1} p(i)$\n",
    "- $\\omega_1(\\tau) = \\sum_{i = \\tau}^{L-1} p(i)$\n",
    "\n",
    "\n",
    "**Question**: Implement this algorithm in a function called ``segmentation_otsu``. Note : only analyse thresholds which produce two distinct regions. Furthemore, remember that the image has only 256 discrete values. Choose the threshold values accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ophvsCCMwJ6L"
   },
   "outputs": [],
   "source": [
    "def segmentation_otsu(img):\n",
    "\n",
    "    min_sigma = np.float('inf')\n",
    "    tau_out = 0\n",
    "    min_level = 0.0\n",
    "    max_level = 255.0\n",
    "    n_levels = 256\n",
    "    for tau in np.linspace(min_level, max_level,n_levels):\n",
    "        # first, get weights of the two regions\n",
    "        omega_0 =XXXXXXXXXXX\n",
    "        omega_1 = XXXXXXXXXX\n",
    "\n",
    "        # only analyse thresholds which give two non-empty regions\n",
    "        if (XXXXXXXXXXXX):\n",
    "            sigma_0 = XXXXXXXXX\n",
    "            sigma_1 = XXXXXXXXXXXX\n",
    "\n",
    "            sigma_total = XXXXXXXXXXXX\n",
    "\n",
    "            if (sigma_total < min_sigma):\n",
    "                tau_out = tau\n",
    "                min_sigma = sigma_total\n",
    "\n",
    "    img_out = np.zeros((img.shape[0],img.shape[1]))\n",
    "    img_out[img<tau_out] = 1\n",
    "    return img_out,tau_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2RatD4pAwiBk"
   },
   "source": [
    "You can apply the Otsu method to segment previously pre-processed images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x5Gd5XCGwiX6"
   },
   "outputs": [],
   "source": [
    "Otsu,tau = segmentation_otsu(imbr)\n",
    "\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "grid = AxesGrid(fig, 111,\n",
    "                nrows_ncols = (1, 2),\n",
    "                axes_pad = 0.5)\n",
    "grid[0].imshow(imbr,cmap='gray')\n",
    "grid[0].axis('off')\n",
    "grid[0].set_title(\"image\")\n",
    "grid[1].imshow(Otsu,cmap='gray')\n",
    "grid[1].axis('off')\n",
    "grid[1].set_title(\"Otsu\")\n",
    "\n",
    "print('The best threshold is {}'.format(tau))\n",
    "print('The dice similarity is ', 1-dice(Otsu.flatten(),im_Seg_r_bool.flatten()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sa9HbZlayF02"
   },
   "source": [
    "One of the problem of the Otsu method it's that there is no notion of connectivity (two regions far away can be in the same region). For such a notion, we turn to region merging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ohCnVqzyXEU"
   },
   "source": [
    "## Region merging\n",
    "\n",
    "The region merging algorithm is quite simple : we start with a small region, and add pixels progressively to the region, according to a criterion. We choose the following criterion :\n",
    "\n",
    "- A pixel $p$ is added to the region if the absolute difference between the pixel value and the region's average value is less than a threshold value (which you must set).\n",
    "\n",
    "First, we can create a function called ``initialize_segmentation`` which initialises the segmentation with a small circular region centred on a given seed point (the seed point is an input). For this, the following function :\n",
    "\n",
    "- scipy.ndimage.morphology.distance_transform_edt\n",
    "\n",
    "can be useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AUgwvJ9eydq1"
   },
   "outputs": [],
   "source": [
    "from scipy.ndimage.morphology import distance_transform_edt\n",
    "\n",
    "def initialize_segmentation(seed_pt,img_shape):\n",
    "    seg_init = np.zeros(img_shape).astype(float)\n",
    "    seg_init[ seed_pt[0], seed_pt[1]] = 1\n",
    "    dist = distance_transform_edt(np.abs(1-seg_init))\n",
    "\n",
    "    # initialise the seeded region with a certain radius\n",
    "    size_radius = 5\n",
    "    seg_init = dist < size_radius\n",
    "    return seg_init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O2Eaiatvyga9"
   },
   "source": [
    "Now, we can create a function called ``segmentation_region_growing`` which carries out the region growing algorithm, with the criterion above, and which uses the ``initialize_segmentation`` function. Again, the functions from ``scipy.ndimage.morphology`` can be useful here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xlZQdcxtymyX"
   },
   "outputs": [],
   "source": [
    "from scipy.ndimage import binary_dilation\n",
    "\n",
    "def segmentation_region_growing(img,seed_pt,tau):\n",
    "\n",
    "    # define the neighbourhood (for instance 4-connected pixels)\n",
    "    nbhood = np.asarray( [ [0,1,0],[1,1,1],[0,1,0]] )\n",
    "\n",
    "    seg_init = initialize_segmentation(seed_pt,img.shape)\n",
    "    seg_n_plus_1 = seg_init\n",
    "    seg_n = np.zeros(seg_n_plus_1.shape)\n",
    "\n",
    "    # loop while the region can still keep growing\n",
    "    while( np.abs(seg_n_plus_1 != seg_n).sum() != 0):\n",
    "        seg_n = seg_n_plus_1\n",
    "        seg_n_plus_1 = binary_dilation(seg_n, structure=nbhood).astype(seg_n.dtype)\n",
    "        # calculate average value\n",
    "        avg = np.sum( img[seg_n>0] ) / ( float(seg_n.sum()))\n",
    "        seg_n_plus_1 = np.logical_and( seg_n_plus_1 , np.abs( img-avg ) < tau)\n",
    "        # do not lose previous points of the segmentation\n",
    "        seg_n_plus_1 = np.logical_or( seg_n_plus_1 , seg_n)\n",
    "\n",
    "    return seg_n,seg_init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gYnnnjn7yo_t"
   },
   "source": [
    "**Question**: Carry out the segmentation on the skin lesion images with the seed point and threshold specified in the following code. The proposed implementation is very simple. We could definitely improve it. Do you see how ? You can simply explain how you would do it or, if you have time, even try to implement it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Q0-Z-22ys81"
   },
   "outputs": [],
   "source": [
    "seed_pt = XXXXXXXXXXXX\n",
    "tau = XXXXXXXXXXXX\n",
    "img_out_region_growing,seg_init = segmentation_region_growing(imbr,seed_pt,tau)\n",
    "\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "grid = AxesGrid(fig, 111,\n",
    "                nrows_ncols = (1, 3),\n",
    "                axes_pad = 0.5)\n",
    "grid[0].imshow(imbr,cmap='gray')\n",
    "grid[0].axis('off')\n",
    "grid[0].set_title(\"image\")\n",
    "grid[1].imshow(seg_init,cmap='gray')\n",
    "grid[1].axis('off')\n",
    "grid[1].set_title(\"Initial region\")\n",
    "grid[2].imshow(img_out_region_growing,cmap='gray')\n",
    "grid[2].axis('off')\n",
    "grid[2].set_title(\"Region growing segmentation\")\n",
    "\n",
    "print('The dice similarity is ', 1-dice(img_out_region_growing.flatten(),im_Seg_r_bool.flatten()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kavXhxtmSxQf"
   },
   "source": [
    "# Graph-Cut\n",
    "You can also use graph-cut, as seen in the previous lecture, to segment the image or to remove hair. You could, for instance, see the hair as noise and try to remove it using the gaussian model or the one of Potts.\n",
    "\n",
    "Here, you can find an example of binary segmentation.\n",
    "\n",
    "**Question**: propose a pipeline, based on graph-cuts and other pre-processing or post-processing methods, to correctly segment the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NpgK538O1fNr"
   },
   "outputs": [],
   "source": [
    "!pip install PyMaxflow\n",
    "import maxflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xSyLIeKm2EF7"
   },
   "outputs": [],
   "source": [
    "beta = 50\n",
    "m1 = 105\n",
    "m2 = 163\n",
    "\n",
    "## Graph cut binaire\n",
    "\n",
    "g = maxflow.Graph[float]()\n",
    "nodeids = g.add_grid_nodes(imbr.shape)\n",
    "g.add_grid_edges(nodeids, beta)\n",
    "g.add_grid_tedges(nodeids, (imbr-m1)**2, (m2-imbr)**2)\n",
    "flow = g.maxflow()\n",
    "sgm = g.get_grid_segments(nodeids)\n",
    "im_bin = 1 - np.int_(np.logical_not(sgm))\n",
    "\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "grid = AxesGrid(fig, 111,\n",
    "                nrows_ncols = (1, 3),\n",
    "                axes_pad = 0.5)\n",
    "grid[0].imshow(imbr,cmap='gray')\n",
    "grid[0].axis('off')\n",
    "grid[0].set_title(\"image\")\n",
    "grid[1].imshow(im_bin,cmap='gray')\n",
    "grid[1].axis('off')\n",
    "grid[1].set_title(\"segmentation mask\")\n",
    "grid[2].imshow(imbr*im_bin,cmap='gray')\n",
    "grid[2].axis('off')\n",
    "grid[2].set_title(\"Result\")\n",
    "\n",
    "print('The dice similarity is ', 1-dice(im_bin.flatten(),im_Seg_r_bool.flatten()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3vEKy_tTC70j"
   },
   "source": [
    "---\n",
    "\n",
    "## SECOND PART\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q3t6BiqcHZsQ"
   },
   "source": [
    "**Question** Please develop a segmentation pipeline using a combination of the previous methods (or others) for at least one of the following applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZGj4n7yHJgdh"
   },
   "source": [
    "## Abdominal CT \n",
    "\n",
    "You have at your disposal 6 abdominal CT scans of different subjects. Subjects may have renal tumor. You also have the manual segmentations for both kidney and, when present, the tumor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9mKuYK2kHtUn"
   },
   "outputs": [],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "  from google_drive_downloader import GoogleDriveDownloader as gdd\n",
    "\n",
    "  gdd.download_file_from_google_drive(file_id='1E-F5x83qaPRUrcdusfyOSgiZWf0pLDFl',\n",
    "                                      dest_path='./abdominalCT.zip',\n",
    "                                      unzip=True)\n",
    "  \n",
    "abdominalCT_path = Working_directory + 'abdominalCT'  \n",
    "!ls './abdominalCT'\n",
    "listImagesabdCT=glob.glob(abdominalCT_path + '/*-seg.tiff')\n",
    "print('There are', len(listImagesabdCT),  'abdomical CT images')\n",
    "print(listImagesabdCT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2wuCpkFhJI6X"
   },
   "outputs": [],
   "source": [
    "from skimage.measure import find_contours\n",
    "\n",
    "# Choose a figure and plot it with the ground truth segmentation\n",
    "indexIm=0 # between 0 and 5\n",
    "\n",
    "# Abdominal CT\n",
    "filename_Segmentation = listImagesabdCT[indexIm]\n",
    "im_Seg = imread(filename_Segmentation)\n",
    "filename = filename_Segmentation[:-9] + '.tiff'\n",
    "imG = imread(filename) \n",
    "\n",
    "print('Reading image ', filename)\n",
    "print(np.unique(im_Seg))\n",
    "\n",
    "if imG.shape != im_Seg.shape:\n",
    "  raise NameError('image and mask should have the same shape, problem...')  \n",
    "\n",
    "# In Im Seg, we may have two values: 127 is for kidney and 255 for renal tumor\n",
    "maskKidney=im_Seg==127\n",
    "if np.sum(maskKidney)==0:\n",
    "  print('There is no kidney')\n",
    "contourMaskKidney = find_contours(maskKidney, 0.5)\n",
    "\n",
    "maskTumor=im_Seg==255\n",
    "if np.sum(maskTumor)==0:\n",
    "  print('There is no tumor')\n",
    "contourMaskTumor = find_contours(maskTumor, 0.5)\n",
    "\n",
    "fig = plt.figure(figsize=(17, 7))\n",
    "grid = AxesGrid(fig, 111,\n",
    "                nrows_ncols = (1, 5),\n",
    "                axes_pad = 0.5)\n",
    "grid[0].imshow(imG, cmap='gray')\n",
    "grid[0].axis('off')\n",
    "grid[0].set_title(\"Original image\")\n",
    "grid[1].imshow(maskKidney,cmap='gray')\n",
    "grid[1].axis('off')\n",
    "grid[1].set_title(\"Segmentation Mask Kidney\")\n",
    "grid[2].imshow(maskTumor,cmap='gray')\n",
    "grid[2].axis('off')\n",
    "grid[2].set_title(\"Segmentation Mask Tumor\")\n",
    "grid[3].imshow(imG, cmap='gray')\n",
    "for contour in contourMaskKidney:\n",
    "  grid[3].plot(contour[:, 1], contour[:, 0], linewidth=2, c='r')\n",
    "grid[3].axis('off')\n",
    "grid[3].set_title(\"Image with mask kidney\")\n",
    "grid[4].imshow(imG, cmap='gray')\n",
    "for contour in contourMaskTumor:\n",
    "  grid[4].plot(contour[:, 1], contour[:, 0], linewidth=2, c='r')\n",
    "grid[4].axis('off')\n",
    "grid[4].set_title(\"Image with mask tumor\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V4Oj-CHzJlij"
   },
   "source": [
    "# Brain MRI\n",
    "\n",
    "Here you can select medial slices of the brain of 4 different subjects. You also have manual segmentations of the corpus callosum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iVCE3g9MJBV8"
   },
   "outputs": [],
   "source": [
    "\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "  from google_drive_downloader import GoogleDriveDownloader as gdd\n",
    "\n",
    "  gdd.download_file_from_google_drive(file_id='1UTSW2nGWV8SBE_ILZQkM-jQvnfoQKDlm',\n",
    "                                      dest_path='./brainMRI.zip',\n",
    "                                      unzip=True)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mXuM2TWJJp1a"
   },
   "outputs": [],
   "source": [
    "brainMRI_path = Working_directory + 'brainMRI'\n",
    "!ls './brainMRI'\n",
    "\n",
    "listImagesbrainMRI=glob.glob(brainMRI_path + '/*-seg.png')\n",
    "print('There are', len(listImagesbrainMRI),  'brain MRI images')\n",
    "print(listImagesbrainMRI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qsn7kKeIJqZe"
   },
   "outputs": [],
   "source": [
    "# Choose a figure and plot it with the ground truth segmentation\n",
    "indexIm=3 # between 0 and 3\n",
    "\n",
    "# Brain MRI\n",
    "filename_Segmentation = listImagesbrainMRI[indexIm]\n",
    "print(filename_Segmentation)\n",
    "im_Seg = imread(filename_Segmentation)\n",
    "filename = filename_Segmentation[:-8] + '.png'\n",
    "imG = imread(filename) \n",
    "\n",
    "print('Reading image ', filename)\n",
    "\n",
    "if imG.shape != im_Seg.shape:\n",
    "  raise NameError('image and mask should have the same shape, problem...')  \n",
    "\n",
    "# In Im Seg we have masks of the corpus callosum\n",
    "maskCC=im_Seg==255\n",
    "contourMask = find_contours(maskCC, 0.5)\n",
    "\n",
    "fig = plt.figure(figsize=(17, 7))\n",
    "grid = AxesGrid(fig, 111,\n",
    "                nrows_ncols = (1, 3),\n",
    "                axes_pad = 0.5)\n",
    "grid[0].imshow(imG, cmap='gray')\n",
    "grid[0].axis('off')\n",
    "grid[0].set_title(\"Original image\")\n",
    "grid[1].imshow(maskCC,cmap='gray')\n",
    "grid[1].axis('off')\n",
    "grid[1].set_title(\"Segmentation Mask\\n Corpus Callosum\")\n",
    "grid[2].imshow(imG, cmap='gray')\n",
    "for contour in contourMask:\n",
    "  grid[2].plot(contour[:, 1], contour[:, 0], linewidth=2, c='r')\n",
    "grid[2].axis('off')\n",
    "grid[2].set_title(\"Image with segmentation\\n corpus callosum\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FZcoktojJtGp"
   },
   "source": [
    "# MRI heart\n",
    "\n",
    "The last section is about MRI sequences of the heart. Your goal is to segment the left ventricule. Be careful, the segmentation is not a maks but a series of points (landmarks). To obtain a binary mask, you should first interpolate the points (using for instance a spline).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4_eWMeBoJYVs"
   },
   "outputs": [],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "  from google_drive_downloader import GoogleDriveDownloader as gdd\n",
    "\n",
    "  gdd.download_file_from_google_drive(file_id='1BZtShVk7LVG032GOlcLs0K4Eaj6gnBed',\n",
    "                                      dest_path='./MRIheart.zip',\n",
    "                                      unzip=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mI3-j5P0JwYZ"
   },
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "\n",
    "\n",
    "MRIheart_path = Working_directory + 'MRIheart/'\n",
    "!ls './MRIheart'\n",
    "\n",
    "data=loadmat(MRIheart_path + 'dataMRIheart.mat')\n",
    "data=data['data']\n",
    "seg=loadmat(MRIheart_path + 'segMRIheart.mat')\n",
    "seg=seg['seg']\n",
    "\n",
    "print('MRI volume of the heart composed of', data.shape[2], 'slices along the z axis and', data.shape[3], \n",
    "'temporal frames. Each slice is an image ', data.shape[0], ' x ',  data.shape[1])\n",
    "print('For each slice and at each time frame we have a manual segmentation composed of',seg[4,4].shape[0] , '2D landmarks')\n",
    "\n",
    "print('Be careful, some slices do not have the left ventricle and the manual segmentation is not simply empty but it contains the value:', seg[0,0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gdtEaCxVJ16-"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 9))\n",
    "plt.suptitle('Different slices at the same time frame with the red manual segmentation at the bottom')\n",
    "plt.subplot(2, 5, 1)\n",
    "plt.imshow(data[:,:,4,1],cmap=\"gray\")\n",
    "plt.gca().invert_yaxis() \n",
    "\n",
    "plt.subplot(2, 5, 2)\n",
    "plt.imshow(data[:,:,5,1],cmap=\"gray\")\n",
    "plt.gca().invert_yaxis() \n",
    "\n",
    "plt.subplot(2, 5, 3)\n",
    "plt.imshow(data[:,:,6,1],cmap=\"gray\")\n",
    "plt.gca().invert_yaxis() \n",
    "\n",
    "plt.subplot(2, 5, 4)\n",
    "plt.imshow(data[:,:,7,1],cmap=\"gray\")\n",
    "plt.gca().invert_yaxis() \n",
    "\n",
    "plt.subplot(2, 5, 5)\n",
    "plt.imshow(data[:,:,8,1],cmap=\"gray\")\n",
    "plt.gca().invert_yaxis() \n",
    "\n",
    "plt.subplot(2, 5, 6)\n",
    "plt.imshow(data[:,:,4,1],cmap=\"gray\")\n",
    "plt.gca().invert_yaxis() \n",
    "plt.scatter(seg[4,1][:,0], seg[4,1][:,1], c='r',alpha=0.1) \n",
    "\n",
    "plt.subplot(2, 5, 7)\n",
    "plt.imshow(data[:,:,5,1],cmap=\"gray\")\n",
    "plt.gca().invert_yaxis() \n",
    "plt.scatter(seg[5,1][:,0], seg[5,1][:,1], c='r',alpha=0.1) \n",
    "\n",
    "plt.subplot(2, 5, 8)\n",
    "plt.imshow(data[:,:,6,1],cmap=\"gray\")\n",
    "plt.gca().invert_yaxis() \n",
    "plt.scatter(seg[6,1][:,0], seg[6,1][:,1], c='r',alpha=0.1) \n",
    "\n",
    "plt.subplot(2, 5, 9)\n",
    "plt.imshow(data[:,:,7,1],cmap=\"gray\")\n",
    "plt.gca().invert_yaxis() \n",
    "plt.scatter(seg[7,1][:,0], seg[7,1][:,1], c='r',alpha=0.1) \n",
    "\n",
    "plt.subplot(2, 5, 10)\n",
    "plt.imshow(data[:,:,8,1],cmap=\"gray\")\n",
    "plt.gca().invert_yaxis() \n",
    "plt.scatter(seg[8,1][:,0], seg[8,1][:,1], c='r',alpha=0.1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_uLxdJl03_H5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9bm3Ljng4KZ-"
   },
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "TP_Seg.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
